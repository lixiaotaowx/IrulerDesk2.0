# 通话质量问题排查与修复日志

## 问题描述
用户反馈观看端（Consumer）听到的音频存在“断断续续”（pulsed/intermittent）的现象，而推流端（Producer）听到的音频正常。
（a电脑作为消费者,b电脑作为生产者时，消费者a说话断断续续，生产者b正常，但是b电脑作为消费者,a电脑作为生产者 双方声音都正常？其中这两台麦克风和喇叭都是一样的设备啊  不存不同设备，啊 真是离奇）
## 排查分析

### 1. 接收端缓冲逻辑差异 (主要原因)
通过对比 `main_capture.cpp` (Producer) 和 `WebSocketReceiver.cpp` (Consumer) 的代码，发现存在关键差异：

*   **Producer (Host)**: 在接收 Peer 音频时，实现了明确的 **抗抖动缓冲 (Anti-Jitter Buffering)** 逻辑。
    *   代码位置: `main_capture.cpp` line 1234-1245
    *   机制: 当队列为空或发生由于欠载导致的缓冲时，会等待队列积攒满 **20帧 (400ms)** 后才开始播放。
    *   效果: 能有效抵抗网络抖动，保证播放连续性。

*   **Consumer (Viewer)**: 在接收 Producer 音频时，**缺少** 相应的抗抖动缓冲逻辑。
    *   代码位置: `WebSocketReceiver.cpp` line 77-118 (修复前)
    *   机制: 只要队列有数据就立即解码播放 (`!m_opusQueue.isEmpty()`)。
    *   后果: 一旦网络微小抖动导致队列暂时为空，立即触发 PLC (丢包隐藏) 或静音，随后数据到达又立即播放，形成“断断续续”的听感。

### 2. 发送机制对比
用户询问是否发送机制不同。经代码审查：
*   **发送**: Producer 使用 20ms 定时器 (`audioTimer`) 采集并发送 Opus 帧。这与标准的 VoIP 模式一致。
*   **传输**: 使用 WebSocket 文本消息 (JSON) 传输 Base64 编码的 Opus 数据。虽然开销较大，但两端机制一致。
*   **结论**: 发送端机制正常，问题主要出在接收端的“零缓冲”策略上。

## 修复方案

已在 `WebSocketReceiver.cpp` 中实现了与 Producer 一致的抗抖动缓冲逻辑：

1.  **新增状态变量**:
    *   在 `WebSocketReceiver.h` 中添加 `bool m_producerBuffering`。
    *   在 `WebSocketReceiver.cpp` 构造函数中初始化为 `true`。

2.  **实现缓冲逻辑**:
    *   修改 `WebSocketReceiver.cpp` 的音频处理循环。
    *   **逻辑**:
        *   初始状态或欠载 (Underrun) 后，进入 `Buffering` 状态。
        *   在 `Buffering` 状态下，暂停解码，直到队列积攒满 **20帧 (400ms)**。
        *   积攒完成后，清除 `Buffering` 标志，开始连续播放。
        *   如果队列再次耗尽，重新进入 `Buffering` 状态。

## 待验证事项

请用户编译并运行最新代码，重点关注：
1.  观看端（Consumer）听推流端（Host）的声音是否变得平滑连续。
2.  是否存在过大的延迟（400ms 缓冲是为了平滑度的必要权衡，通常可接受）。
- 统一预缓冲门限为 20 帧
  - 位置： src/player/WebSocketReceiver.cpp:618–630 、 682–696
  - 将音频定时器的启动门槛统一改为 20 帧，并在启动时重置 m_producerBuffering = true ，和解码门控保持一致，避免“初次 50/重启 15”与解码门限不一致导致的抖动。
- 播放设备恢复悬挂状态
  - 位置： src/video_components/AudioPlayer.cpp:140–149
  - 当 QAudioSink 处于 SuspendedState 时主动执行 resume() ，修复设备短时数据不足后不自动恢复导致的间歇性停顿。
- 修复编译错误的日志变量
  - 位置： src/player/WebSocketReceiver.cpp:116–121
  - 日志中的 PLC: 标识改为使用 !hasFrame ，已替换掉未定义的 isPLC 。
端到端通路

- 采集与发送（Producer）
  - 麦克风按设备支持采样率协商，20ms 帧编码，JSON + Base64 承载 Opus。
  - 参考： src/capture/main_capture.cpp:660–727
- 接收与入队（Consumer）
  - 将音频计时器启动门槛统一为 20 帧；入队同时执行队列长度限幅（避免过度积压导致高延迟）。
  - 参考： src/player/WebSocketReceiver.cpp:600–631
- 解码与混音（Consumer）
  - Producer 主流新增“抗抖动缓冲”门控：队列达 20 帧后才解码；欠载自动回到缓冲态。
  - 欠载软容错：最多 20 帧（400ms）静音以维持设备工作，不至于停摆。
  - 参考： src/player/WebSocketReceiver.cpp:232–259
 - 播放设备（Consumer）
  - Push 模式写入 QAudioSink 的 IO 设备；StoppedState 时 start() 重启，SuspendedState 时 resume() 恢复。
  - 参考： src/video_components/AudioPlayer.cpp:140–171

---

## 第三轮定位与改动（非常规实现修复）

- 非常规实现：音频写入丢失
  - 位置： src/video_components/AudioPlayer.cpp:161
  - 问题：当设备一次性无法写完整帧时，余下数据被直接丢弃，形成可闻空洞与“断断续续”。
  - 方案：引入环形缓冲，将帧加入 m_ringBuffer，循环写入直至设备不再接收；剩余保留以便后续继续写出。

- 设备状态恢复强化
  - 位置： src/video_components/AudioPlayer.cpp:140–149
  - 逻辑： StoppedState 下 start()； SuspendedState 下 resume()，覆盖蓝牙/虚拟声卡等易挂起设备。

- 接收端门槛一致化
  - 位置： src/player/WebSocketReceiver.cpp:618–630 、 682–696
  - 将所有启动门槛统一为 20 帧，与解码门控一致，降低“预缓冲/解码”门槛不一致造成的节拍抖动。

---

## 第四轮：降低延迟与设备差异解释

- 降低播放侧输出缓冲以减少总延迟
  - 位置： src/video_components/AudioPlayer.cpp:275
  - 将 `QAudioSink` 缓冲由约 1000ms 降至约 500ms，以减少端到端延迟，同时保留环形缓冲避免写入丢失。

- 降低接收端预缓冲门槛以缩短启动时延
  - 位置： src/player/WebSocketReceiver.cpp:616–630 、 682–696 、 80–88 、 161–170
  - 将 Producer 主流与 Peer 的抗抖动缓冲门槛从 20 帧降至 12 帧（约 240ms），在保持平滑度的同时进一步降低语音起播延迟。

- 设备差异导致链路不一致的解释
  - 即便两台机器连接相同麦克风/喇叭，系统的默认输入设备、驱动缓冲策略与支持采样率协商结果仍可能不同。
  - 已在消费者的本地采集链路中增加“设备自适应采样率协商”和“合理输入缓冲大小”，以减小不同机器的差异带来的间歇现象。

## 建议验证方法

- 直接编译运行观看端，关注是否仍有节律性断音。
- 若设备是蓝牙或虚拟声卡，观察短时无声后是否能自动恢复。
- 如仍存在问题，请记录出现时间点与设备状态（尤其 SuspendedState/StoppedState），并提供复制的日志内容。

---

## 第五轮：高精度定时器与系统定时分辨率（降延迟与稳节拍）

- 高精度定时器
  - 位置： `src/player/WebSocketReceiver.cpp:61`、`src/player/WebSocketReceiver.cpp:1341`
  - 为 `m_audioTimer` 与本地采集 `m_localAudioTimer` 设置 `Qt::PreciseTimer`，避免在 Windows 默认 15.6ms Tick 下造成 20ms/5ms 节拍抖动与“追赶爆发”。

- Windows 1ms 定时分辨率
  - 位置： `src/player/main_player.cpp:12–13, 21, 106, 132`
  - 在进程启动调用 `timeBeginPeriod(1)`，退出调用 `timeEndPeriod(1)`，保证短周期定时器的稳定性。

- 播放侧缓冲降至约 200ms
  - 位置： `src/video_components/AudioPlayer.cpp:...`（`setBufferSize(... / 5)`）
  - 将 `QAudioSink` 缓冲由约 500ms 下调到约 200ms，在保留环形写入防丢的前提下进一步降低端到端延迟。

---

## 外部参考与可借鉴实践（针对“别人如何解决”）

- WebRTC NetEQ 抖动缓冲设计与 PLC/FEC
  - 参考： webrtcHacks《NetEQ 抖动缓冲如何实现平滑音频》 [webrtcHacks, 2023]
  - 要点：自适应抖动缓冲（快速增大、缓慢缩小）、PLC 生成、Opus In-band FEC/RED、NACK 重传等共同保证语音连续性。

- 抖动缓冲的尺寸与策略
  - 参考： GetStream《WebRTC and Buffers》说明音频抖动缓冲通常在 15–120ms 范围，随网络抖动动态调整。
  - 我们的实现当前为“固定预缓冲 + 欠载软静音 + FEC 解码”，后续可考虑“自适应门限 + 欠载统计”。

- Qt 定时器与高分辨率技巧
  - 参考： StackOverflow《Qt 高分辨率定时器与 QElapsedTimer 用法》、Qt Forum 关于 QAudioSink/QTimer 在 Windows 的精度差异讨论。
  - 实践：为音频相关定时器使用 `Qt::PreciseTimer`，必要时启用 `timeBeginPeriod(1)` 以确保 1ms Tick。

（引用来源：
  - [StackOverflow: Changing Qt's timer resolution on Windows](https://stackoverflow.com/questions/24602202/changing-qts-timer-resolution-on-windows)
  - [Qt 6 QAudioSink 文档](https://doc.qt.io/qt-6/qaudiosink.html)
  - [webrtcHacks: How WebRTC’s NetEQ Jitter Buffer Provides Smooth Audio](https://webrtchacks.com/how-webrtcs-neteq-jitter-buffer-provides-smooth-audio/)
  - [GetStream: WebRTC and Buffers](https://getstream.io/resources/projects/webrtc/advanced/buffers/)
)

---

## 设备差异与检查清单（A 机器作为消费者断续，B 正常）

- 操作系统层面
  - 电源计划设为“高性能”，禁用 CPU 节能（C-State 深度）、PCIe 省电（Link State Power Management）。
  - 网卡属性关闭“允许计算机关闭此设备以节约电源”，检查驱动版本一致。

- 声卡/驱动层面
  - 关闭系统“音频增强”（Enhancements），确认默认格式与我们使用的格式一致（首选 Int16；采样率由设备支持自动协商）。
  - 更新到同一驱动版本；若为蓝牙设备，优先使用稳定的编码路径（避免 SCO 品质波动）。

- 系统定时分辨率
  - 通过上述 `timeBeginPeriod(1)` 已在进程内提升；如系统中有其他软件动态修改分辨率，可能导致节拍差异。

- 网络路径与 CPU 负载
  - 由于消费者侧仍使用 JSON + Base64 文本消息承载 Opus，低端 CPU 或高负载时会增加解析开销；后续可评估改为二进制消息以进一步降开销（属较大改动，待评估）。

---

## 下一步（可选的更大改动方向，需单独构建验证）

- 将音频帧改用 WebSocket 二进制消息（自定义简洁头 + 原始帧），替代 JSON/Base64，降低 20ms 周期的序列化/解析开销与 GC 压力。
- 引入“自适应抖动缓冲”策略：基于到达时间与序列号统计，动态调整预缓冲门限与欠载处理窗口，参考 NetEQ 的“快速增、慢速减”策略。

---

## 第六轮：麦克风开关语义调整（只影响自身）

- 背景：此前“观众端麦克风开关”会同时下发 `audio_toggle` 到采集端，导致观看端关闭麦克风时，采集端也被关闭，违背“各自控制自己的麦克风”的直觉。

- 改动：
  - 位置： `src/video_components/VideoDisplayWidget.cpp:115–116`
    - 移除在 `connected` 阶段自动调用 `sendAudioToggle(m_micSendEnabled)`，避免连上即控制对端麦克风。
  - 位置： `src/MainWindow.cpp:1586–1588`
    - 在 `onMicToggleRequested` 中移除 `vd->sendAudioToggle(enabled)`，改为仅 `vd->setTalkEnabled(enabled)` 与 `vd->setMicSendEnabled(enabled)`，实现“只控制自己能否说话”。

- 结果：
  - 消费者关闭麦克风 ⇒ 只影响自己“能不能说话”，不会让生产者也不能说话。
  - 如需控制对端是否采集（特殊场景），保留 `sendAudioToggle(...)` API，后续可在独立的“远端麦克风开关”入口中使用。
